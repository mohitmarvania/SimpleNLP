# ğŸ“ SimpleNLP - Natural language Processing from Scratch

SimpleNLP is an **educational** and **lightweight** natural language processing (NLP) library I have implemented, where key NLP models are implemented using only **NumPy**, **Pandas**, **Scikit-learn** and Python in-built libraries. No external deep learning frameworks like PyTorch and TensorFlow was used! ğŸš€ This was to understand how NLP processes data from ground level.

This project includes implementations of **tokenization, word embeddings, classifiers, RNNs, and Transformers**, followed by two **real-world NLP tasks**:

1. **Text Classification** ğŸ·ï¸ (Sentiment Analysis on Twitter Data)
2. **Text Generation** ğŸ“ (Shakespeare-style text generation)

Although the models are **simplified**, they still provide valuable insights into how NLP techniques work under the hood! ğŸ’¡

---

## ğŸ“‚ Project Structure

```
SimpleNLP/
â”‚â”€â”€ SimpleNLP/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tokenization.py      # Tokenizer & Vectorization
â”‚   â”œâ”€â”€ embeddings.py        # Word2Vec & GloVe
â”‚   â”œâ”€â”€ classifiers.py       # Logistic Regression, Feedforward NN
â”‚   â”œâ”€â”€ rnn.py               # Simple RNN implementation
â”‚   â”œâ”€â”€ transformer.py       # Basic Transformer encoder
â”‚   â”œâ”€â”€ utils.py             # Helper functions
â”‚â”€â”€ examples/
â”‚   â”œâ”€â”€ text_classification.py
â”‚   â”œâ”€â”€ text_generation.py
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
```

---

## ğŸš€ Features

âœ… **Tokenization & Vectorization** (Word & Char tokenization, NGramTokenizer, Byte-Pair Tokenizer)  
âœ… **Word Embeddings** (Word2Vec, TFIDFVectorizer)  
âœ… **Machine Learning Classifiers** (Logistic Regression, Feedforward NN)  
âœ… **Recurrent Neural Networks (RNN)** (Implemented from scratch)  
âœ… **Transformers** (Basic Transformer)  
âœ… **Example NLP Tasks** (Sentiment Analysis, Text Generation)

---

## ğŸ† Example NLP Tasks

### **ğŸ“Œ 1. Text Classification (Twitter Sentiment Analysis)**

- **Dataset**: Twitter Sentiment Analysis (~74,683 training examples, ~1,000 testing examples)
- **Objective**: Classify tweets as positive/negative/neutral
- **Training**: Only trained on **7,000 samples** due to computational constraints
- **Accuracy**: ~66%

ğŸ“Œ **Run Example:**

```bash
python examples/text_classification.py
```

### **ğŸ“Œ 2. Text Generation (Shakespeare-Style)**

- **Objective**: Generate Shakespeare-style text using a Transformer-based model
- **Dataset**: Shakespeare corpus
- **Challenges**:
- Transformer was implemented from scratch using NumPy.
- No automatic differentiation or deep learning optimizers used.
- Text quality is not perfect, but it generates somewhat meaningful content.
  ğŸ“Œ Run Example:

```bash
python examples/text_generation.py
```

---

ğŸ›  Installation
1ï¸âƒ£ Clone the repository

```
git clone https://github.com/mohitmarvania/SimpleNLP.git
cd SimpleNLP
```

2ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

3ï¸âƒ£ Run example scripts

```
python examples/text_classification.py
python examples/text_generation.py
```

---

ğŸ“š Dependencies
Python 3.x
NumPy
Pandas
Scikit-learn
ğŸ“Œ Install all dependencies using:

```
pip install -r requirements.txt
```

---

ğŸš€ Future Improvements
âœ… Implement Attention Mechanism in Transformer
âœ… Add LSTM and GRU models
âœ… Improve Optimizers for better training
âœ… Expand NLP applications (e.g., Named Entity Recognition)

ğŸ¤ Contributing
Contributions are welcome! Feel free to open issues and submit pull requests. ğŸ› ï¸

ğŸ“œ License
This project is licensed under the MIT License.
